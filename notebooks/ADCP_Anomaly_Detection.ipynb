{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the next step from \"ADCP_Anomaly_Training.ipynb\"\n",
    "\n",
    "#Now that I have a trained model (trained on BACAX data), lets try to implement it to find drop-outs \n",
    "#I am applying this to find drop-outs in BACUS 2 MHZ data\n",
    "\n",
    "#Kernel:\n",
    "#adcp_anomaly_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO: CONSIDER REVISING THE CODE SO ALL 24hr FILES CLASSIFY AT ONCE!\n",
    "#   Classifying 1 file at a time is slow!\n",
    "#Then, Print list of times/beams that have drop-outs, then can run plots seperately after! \n",
    "# => DONE!\n",
    "\n",
    "\n",
    "# Add repo root to Python path - Needed to import from src folder\n",
    "import sys\n",
    "from pathlib import Path\n",
    "repo_root = Path().resolve().parent  # notebooks/ â†’ ADCP-CNN-QAQC\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "#I used to code above to create a new function and several methods\n",
    "import os\n",
    "from src import detect_nortek_dropouts\n",
    "\n",
    "#For Debugging:\n",
    "import importlib\n",
    "importlib.reload(detect_nortek_dropouts)\n",
    "\n",
    "\n",
    "# Monthly Mat data to convert (directory path, it will find the mat files)\n",
    "data_parent = r'F:\\Documents\\Projects\\ADCP\\scan_for_data\\BACUS\\ADCP2MHZ\\\\'\n",
    "\n",
    "#For one specific folder:\n",
    "#folder_list = ['20240801']\n",
    "\n",
    "folder_list = ['20131101', '20141201', '20161101', '20170501', \n",
    "                '20220101', '20220201', '20220601', '20220801',\n",
    "                '20221001', '20230201', '20230701', '20240201',\n",
    "                '20240801', '20250201']\n",
    "\n",
    "# folder_list = ['20250701']\n",
    "\n",
    "\n",
    "#For many folders\n",
    "#child_folders = os.listdir(data_parent)\n",
    "#folder_list = child_folders[-12:-1]\n",
    "\n",
    "#Inputs:\n",
    "variant = 'resnet50'\n",
    "#variant = 'TemporalCNN'\n",
    "\n",
    "if variant == 'TemporalCNN':\n",
    "    model_path = r\"F:\\Documents\\GitHub\\ml_development\\ADCP_ML\\\\\" + \"best_model_20250508.pt\"\n",
    "else:\n",
    "    model_path = r\"F:\\Documents\\GitHub\\ml_development\\ADCP_ML\\\\\" + f\"best_model_{variant}.pt\"\n",
    "\n",
    "h5_monthly_folder = r'F:\\Documents\\Projects\\ML\\ADCP_ML\\BACUS\\h5_files\\\\' # Define output folder -  Monthly h5\n",
    "h5_24hr_folder = r'F:\\Documents\\Projects\\ML\\ADCP_ML\\BACUS\\h5_24h_files\\\\'  #Output folder - 24hr h5:\n",
    "\n",
    "do_delete = 1\n",
    "\n",
    "#Create a text file for keeping track of detections:\n",
    "log_path = os.path.join(h5_24hr_folder, f\"dropout_detections_{variant}.txt\")\n",
    "# Create or clear the file\n",
    "with open(log_path, \"w\") as f:\n",
    "    f.write(\"start_time, end_time, class, beam, duration_minutes\\n\")\n",
    "\n",
    "\n",
    "for folder in folder_list:\n",
    "    # Path to your .mat file\n",
    "    file_list = os.listdir(data_parent + folder)\n",
    "    mat_files = {k for k in file_list if os.path.splitext(k)[1] == \".mat\"}\n",
    "    print(mat_files)\n",
    "\n",
    "    #Combine the filenames into a proper path:\n",
    "    mat_paths = []\n",
    "    for filename in mat_files:\n",
    "        mat_paths.append(data_parent + folder + '\\\\' + filename) \n",
    "\n",
    "    #Run the extraction\n",
    "    for mat_path in mat_paths:\n",
    "        detect_nortek_dropouts.run_classify(model_path, mat_path, h5_monthly_folder, h5_24hr_folder, log_path, create_plots = 0) \n",
    "        #detect_nortek_dropouts.run_classify(model_path, mat_path, h5_monthly_folder, h5_24hr_folder) \n",
    "\n",
    "        if do_delete:\n",
    "            # After detection and plotting, delete all .h5 files\n",
    "            for h5_folder in {h5_monthly_folder, h5_24hr_folder}:\n",
    "                file_list = os.listdir(h5_folder)\n",
    "                h5_files = sorted(k for k in file_list if k.endswith(\".h5\"))\n",
    "\n",
    "                for h5_file in h5_files:\n",
    "                    full_path = os.path.join(h5_folder, h5_file)\n",
    "                    try:\n",
    "                        os.remove(full_path)\n",
    "                        print(f\"Deleted {h5_file}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to delete {h5_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO: CONSIDER REVISING THE CODE SO ALL 24hr FILES CLASSIFY AT ONCE!\n",
    "#   Classifying 1 file at a time is slow!\n",
    "#Then, Print list of times/beams that have drop-outs, then can run plots seperately after! \n",
    "# => DONE!\n",
    "\n",
    "#I used to code above to create a new function and several methods\n",
    "import os\n",
    "from src import detect_nortek_dropouts\n",
    "\n",
    "#For Debugging:\n",
    "import importlib\n",
    "importlib.reload(detect_nortek_dropouts)\n",
    "\n",
    "\n",
    "# Monthly Mat data to convert (directory path, it will find the mat files)\n",
    "data_parent = r'F:\\Documents\\Projects\\ADCP\\scan_for_data\\BACUS\\ADCP2MHZ\\\\'\n",
    "\n",
    "#For one specific folder:\n",
    "#folder_list = ['20240801']\n",
    "\n",
    "folder_list = ['20131101', '20141201', '20161101', '20170501', \n",
    "                '20220101', '20220201', '20220601', '20220801',\n",
    "                '20221001', '20230201', '20230701', '20240201',\n",
    "                '20240801', '20250201']\n",
    "\n",
    "# folder_list = ['20250701']\n",
    "\n",
    "\n",
    "#For many folders\n",
    "#child_folders = os.listdir(data_parent)\n",
    "#folder_list = child_folders[-12:-1]\n",
    "\n",
    "#Inputs:\n",
    "variant = 'resnet50'\n",
    "#variant = 'TemporalCNN'\n",
    "\n",
    "if variant == 'TemporalCNN':\n",
    "    model_path = r\"F:\\Documents\\GitHub\\ml_development\\ADCP_ML\\\\\" + \"best_model_20250508.pt\"\n",
    "else:\n",
    "    model_path = r\"F:\\Documents\\GitHub\\ml_development\\ADCP_ML\\\\\" + f\"best_model_{variant}.pt\"\n",
    "\n",
    "h5_monthly_folder = r'F:\\Documents\\Projects\\ML\\ADCP_ML\\BACUS\\h5_files\\\\' # Define output folder -  Monthly h5\n",
    "h5_24hr_folder = r'F:\\Documents\\Projects\\ML\\ADCP_ML\\BACUS\\h5_24h_files\\\\'  #Output folder - 24hr h5:\n",
    "\n",
    "do_delete = 0\n",
    "\n",
    "#Create a text file for keeping track of detections:\n",
    "log_path = os.path.join(h5_24hr_folder, f\"dropout_detections_{variant}.txt\")\n",
    "# Create or clear the file\n",
    "with open(log_path, \"w\") as f:\n",
    "    f.write(\"start_time, end_time, class, beam, duration_minutes\\n\")\n",
    "\n",
    "\n",
    "mat_paths = []\n",
    "for folder in folder_list:\n",
    "    # Path to your .mat file\n",
    "    file_list = os.listdir(data_parent + folder)\n",
    "    mat_files = {k for k in file_list if os.path.splitext(k)[1] == \".mat\"}\n",
    "    print(mat_files)\n",
    "\n",
    "    #Combine the filenames into a proper path:\n",
    "    \n",
    "    for filename in mat_files:\n",
    "        mat_paths.append(data_parent + folder + '\\\\' + filename) \n",
    "\n",
    "#Run the extraction\n",
    "for mat_path in mat_paths:\n",
    "    detect_nortek_dropouts.run_classify(model_path, mat_path, h5_monthly_folder, h5_24hr_folder, log_path, create_plots = 0) \n",
    "    #detect_nortek_dropouts.run_classify(model_path, mat_path, h5_monthly_folder, h5_24hr_folder) \n",
    "\n",
    "    if do_delete:\n",
    "        # After detection and plotting, delete all .h5 files\n",
    "        for h5_folder in {h5_monthly_folder, h5_24hr_folder}:\n",
    "            file_list = os.listdir(h5_folder)\n",
    "            h5_files = sorted(k for k in file_list if k.endswith(\".h5\"))\n",
    "\n",
    "            for h5_file in h5_files:\n",
    "                full_path = os.path.join(h5_folder, h5_file)\n",
    "                try:\n",
    "                    os.remove(full_path)\n",
    "                    print(f\"Deleted {h5_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to delete {h5_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre10/scratch/slonimer'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Initializing ResNet model (resnet34)\n",
      "\n",
      "=== Starting Evaluation on Test Set ===\n",
      "Running drop-out detection on all 24 hr files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Apply on Rorqual to pre-made h5 files\n",
    "\n",
    "#TODO: CONSIDER REVISING THE CODE SO ALL 24hr FILES CLASSIFY AT ONCE!\n",
    "#   Classifying 1 file at a time is slow!\n",
    "#Then, Print list of times/beams that have drop-outs, then can run plots seperately after! \n",
    "# => DONE!\n",
    "\n",
    "#I used to code above to create a new function and several methods\n",
    "import os\n",
    "from src import detect_nortek_dropouts\n",
    "\n",
    "#For Debugging:\n",
    "import importlib\n",
    "importlib.reload(detect_nortek_dropouts)\n",
    "\n",
    "#Inputs:\n",
    "variant = 'resnet34'\n",
    "#variant = 'TemporalCNN'\n",
    "\n",
    "model_path = \"best_model_4_resnet34_bs16.pt\"\n",
    "\n",
    "#Already converted to daily h5, so can set these to none\n",
    "mat_path = None\n",
    "h5_monthly_folder = None\n",
    "\n",
    "#Folder with 24hr h5 files\n",
    "h5_24hr_folder = '/lustre10/scratch/slonimer/BACUS_24hr_h5_test/'\n",
    "\n",
    "\n",
    "#Create a text file for keeping track of detections:\n",
    "log_path = os.path.join(h5_24hr_folder, f\"dropout_detections_{variant}.txt\")\n",
    "# Create or clear the file\n",
    "with open(log_path, \"w\") as f:\n",
    "    f.write(\"start_time, end_time, class, beam, duration_minutes\\n\")\n",
    "\n",
    "\n",
    "#Run the extraction\n",
    "detect_nortek_dropouts.run_classify(model_path, mat_path, h5_monthly_folder, h5_24hr_folder, log_path, create_plots = 0) \n",
    "#detect_nortek_dropouts.run_classify(model_path, mat_path, h5_monthly_folder, h5_24hr_folder) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Can I apply this to the anomalous examples used for training?\n",
    "\n",
    "import os\n",
    "from src import detect_nortek_dropouts\n",
    "\n",
    "#For Debugging:\n",
    "import importlib\n",
    "importlib.reload(detect_nortek_dropouts)\n",
    "\n",
    "#For ALL anomalous files, plot the annotations and the prediction\n",
    "\n",
    "#Initialize the classification model\n",
    "model_path = r\"F:\\Documents\\GitHub\\ml_development\\ADCP_ML\\\\\" + \"best_model_20250508.pt\"\n",
    "model = detect_nortek_dropouts.init_model(model_path)\n",
    "\n",
    "#Define anomaly file paths\n",
    "file_path = r\"F:\\Documents\\Projects\\ML\\ADCP_ML\\h5_24h_files\\\\\"\n",
    "\n",
    "#Create a text file for keeping track of detections:\n",
    "log_path = os.path.join(file_path, \"dropout_detections.txt\")\n",
    "# Create or clear the file\n",
    "with open(log_path, \"w\") as f:\n",
    "    f.write(\"start_time, end_time, class, beam, duration_minutes\\n\")\n",
    "    \n",
    "# Extract anomaly filenames from a text file\n",
    "with open(r\"F:\\Documents\\Projects\\ML\\ADCP_ML\\\\\" + \"annotated_files.txt\", \"r\") as f:\n",
    "    #anomaly_files = set(line.strip() for line in f if line.strip())\n",
    "    anomaly_files = list(dict.fromkeys(line.strip() for line in f if line.strip()))\n",
    "\n",
    "#Run the classification and plots:\n",
    "detect_nortek_dropouts.classify_and_plot(model, anomaly_files, file_path)\n",
    "#detect_nortek_dropouts.classify_and_plot(model, h5_files, h5_24hr_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20130619T000000_20130619T235959.h5', '20130620T000000_20130620T235959.h5', '20140829T000000_20140829T235959.h5', '20140830T000000_20140830T235959.h5', '20170830T235731_20170831T235730.h5', '20170901T000230_20170902T000229.h5', '20171118T000000_20171118T235959.h5', '20171119T000000_20171119T235959.h5', '20171120T000000_20171120T235959.h5', '20190511T000000_20190511T235959.h5', '20190512T000000_20190512T235959.h5', '20230624T000000_20230624T235959.h5', '20230625T000000_20230625T235959.h5', '20230701T000230_20230702T000229.h5', '20230702T000000_20230702T235959.h5', '20230703T000000_20230703T235959.h5', '20231114T000000_20231114T235959.h5', '20231115T000000_20231115T235959.h5', '20231116T000000_20231116T235959.h5', '20231117T000000_20231117T235959.h5', '20231118T000000_20231118T235959.h5', '20240406T000000_20240406T235959.h5', '20240625T000000_20240625T235959.h5', '20240626T000000_20240626T235959.h5', '20240627T000000_20240627T235959.h5', '20240628T000000_20240628T235959.h5', '20240629T000000_20240629T235959.h5', '20240701T000230_20240702T000229.h5', '20240702T000000_20240702T235959.h5', '20241027T000000_20241027T235959.h5', '20241028T000000_20241028T235959.h5', '20241029T000000_20241029T235959.h5', '20241030T000000_20241030T235959.h5', '20241030T235731_20241031T235730.h5', '20241230T000000_20241230T235959.h5', '20241230T235731_20241231T235730.h5', '20250101T000230_20250102T000229.h5']\n"
     ]
    }
   ],
   "source": [
    "print(anomaly_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adcp_anomaly_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
